{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from pyspark import SparkContext\n",
    "sc =SparkContext()\n",
    "\n",
    "from pyspark.sql import SQLContext\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer, VectorIndexer, MinMaxScaler\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder, TrainValidationSplit\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sqlContext.read.format('csv').options(header='true', inferSchema='true').load('frauddetectionsmall.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[step: int, type: string, amount: double, nameOrig: string, oldbalanceOrg: double, newbalanceOrig: double, nameDest: string, oldbalanceDest: double, newbalanceDest: double, isFraud: int, isFlaggedFraud: int]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- step: integer (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- amount: double (nullable = true)\n",
      " |-- nameOrig: string (nullable = true)\n",
      " |-- oldbalanceOrg: double (nullable = true)\n",
      " |-- newbalanceOrig: double (nullable = true)\n",
      " |-- nameDest: string (nullable = true)\n",
      " |-- oldbalanceDest: double (nullable = true)\n",
      " |-- newbalanceDest: double (nullable = true)\n",
      " |-- isFraud: integer (nullable = true)\n",
      " |-- isFlaggedFraud: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[type: string, amount: double, oldbalanceOrg: double, newbalanceOrig: double, oldbalanceDest: double, newbalanceDest: double, label: int]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#select data column\n",
    "df2 = df.select(\"type\", \"amount\", \"oldbalanceOrg\", \"newbalanceOrig\", \"oldbalanceDest\", \"newbalanceDest\", (col(\"isFraud\").cast(\"Int\").alias(\"label\")))\n",
    "display(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data\n",
    "splits = df2.randomSplit([0.7, 0.3])\n",
    "train = splits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = splits[1].withColumnRenamed(\"label\", \"trueLabel\")\n",
    "train_rows = train.count()\n",
    "test_rows = test.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Rows: 7126  Testing Rows: 3074\n",
      "+-------+-------+-------------+--------------+--------------+--------------+-----+\n",
      "|   type| amount|oldbalanceOrg|newbalanceOrig|oldbalanceDest|newbalanceDest|label|\n",
      "+-------+-------+-------------+--------------+--------------+--------------+-----+\n",
      "|CASH_IN| 484.57|   5422437.76|    5422922.33|    5638778.53|    5579568.65|    0|\n",
      "|CASH_IN| 863.08|   9290756.54|    9291619.62|       5577.88|        4714.8|    0|\n",
      "|CASH_IN|1076.27|   3538789.28|    3539865.55|      22774.25|      23539.55|    0|\n",
      "|CASH_IN| 1252.3|    2843880.9|     2845133.2|     145455.99|      144203.7|    0|\n",
      "|CASH_IN|1332.59|   2533796.06|    2535128.65|        8693.0|       7360.41|    0|\n",
      "+-------+-------+-------------+--------------+--------------+--------------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-------+-------+-------------+--------------+--------------+--------------+---------+\n",
      "|   type| amount|oldbalanceOrg|newbalanceOrig|oldbalanceDest|newbalanceDest|trueLabel|\n",
      "+-------+-------+-------------+--------------+--------------+--------------+---------+\n",
      "|CASH_IN| 270.78|   4184966.65|    4185237.43|        3019.0|           0.0|        0|\n",
      "|CASH_IN| 783.31|   8150331.93|    8151115.24|       2013.12|       1229.81|        0|\n",
      "|CASH_IN| 833.39|    3856002.2|    3856835.59|     411058.34|     410224.95|        0|\n",
      "|CASH_IN| 911.76|   1335635.48|    1336547.24|       48321.6|      47409.85|        0|\n",
      "|CASH_IN|1271.77|    6973823.5|    6975095.27|     697456.73|    2719172.89|        0|\n",
      "+-------+-------+-------------+--------------+--------------+--------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (\"Training Rows:\", train_rows, \" Testing Rows:\", test_rows)\n",
    "train.show(5)\n",
    "test.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- type: string (nullable = true)\n",
      " |-- amount: double (nullable = true)\n",
      " |-- oldbalanceOrg: double (nullable = true)\n",
      " |-- newbalanceOrig: double (nullable = true)\n",
      " |-- oldbalanceDest: double (nullable = true)\n",
      " |-- newbalanceDest: double (nullable = true)\n",
      " |-- trueLabel: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining Pipeline whihc provides a simple construction, tuning and testing for ML workflows.\n",
    "strIdx = StringIndexer(inputCol = \"type\", outputCol = \"typeCat\")\n",
    "labelIdx = StringIndexer(inputCol = \"label\", outputCol = \"idxLabel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number is meaningful so that it should be number features\n",
    "catVect = VectorAssembler(inputCols = [\"typeCat\"], outputCol=\"catFeatures\")\n",
    "catIdx = VectorIndexer(inputCol = catVect.getOutputCol(), outputCol = \"idxCatFeatures\")\n",
    "numVect = VectorAssembler(inputCols = [\"amount\", \"oldbalanceOrg\", \"newbalanceOrig\", \"oldbalanceDest\", \"newbalanceDest\"], outputCol=\"numFeatures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number vector is normalized\n",
    "minMax = MinMaxScaler(inputCol = numVect.getOutputCol(), outputCol=\"normFeatures\")\n",
    "featVect = VectorAssembler(inputCols=[\"idxCatFeatures\", \"normFeatures\"], outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl = []\n",
    "pipeline = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl.insert(0, DecisionTreeClassifier(labelCol=\"idxLabel\", featuresCol=\"features\"))\n",
    "cl.insert(1, RandomForestClassifier(labelCol=\"idxLabel\", featuresCol=\"features\"))\n",
    "cl.insert(2, LogisticRegression(labelCol=\"idxLabel\", featuresCol=\"features\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline complete!\n"
     ]
    }
   ],
   "source": [
    "# Pipeline process the series of transformation above, which is 7 transformation\n",
    "for i in range(3):\n",
    "    pipeline.insert(i, Pipeline(stages=[strIdx, labelIdx, catVect, catIdx, numVect, minMax, featVect, cl[i]]))\n",
    "    #piplineModel = pipeline.fit(train)\n",
    "print (\"Pipeline complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 completed\n"
     ]
    }
   ],
   "source": [
    "#Train Validation Split\n",
    "#we will used a train validation split instead of cross validation for every model because it takes much less time to train the model with the train validation split.\n",
    "model = []\n",
    "\n",
    "#When we will be using the whole dataset, we will use the TrainValidationSplit instead of the CrossValidator!\n",
    "paramGrid = (ParamGridBuilder().addGrid(cl[0].impurity, (\"gini\", \"entropy\")).addGrid(cl[0].maxDepth, [5, 10, 20]).addGrid(cl[0].maxBins, [5, 10, 20]).build())\n",
    "cv = CrossValidator(estimator=pipeline[0], evaluator=BinaryClassificationEvaluator(), estimatorParamMaps=paramGrid, numFolds=5)\n",
    "#cv = TrainValidationSplit(estimator=pipeline[0], evaluator=BinaryClassificationEvaluator(), estimatorParamMaps=paramGrid, trainRatio=0.8)\n",
    "model.insert(0, cv.fit(train))\n",
    "print (\"Model 1 completed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 2 completed\n"
     ]
    }
   ],
   "source": [
    "paramGrid2 = (ParamGridBuilder().addGrid(cl[1].impurity, (\"gini\", \"entropy\")).addGrid(cl[1].maxDepth, [5, 10, 20]).addGrid(cl[1].maxBins, [5, 10, 20]).build())\n",
    "cv2 = CrossValidator(estimator=pipeline[1], evaluator=BinaryClassificationEvaluator(), estimatorParamMaps=paramGrid2, numFolds=5)\n",
    "#cv2 = TrainValidationSplit(estimator=pipeline[1], evaluator=BinaryClassificationEvaluator(), estimatorParamMaps=paramGrid2, trainRatio=0.8)\n",
    "model.insert(1, cv2.fit(train))\n",
    "print (\"Model 2 completed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 3 completed\n"
     ]
    }
   ],
   "source": [
    "paramGrid3 = (ParamGridBuilder().addGrid(cl[2].regParam, [0.01, 0.5, 2.0]).addGrid(cl[2].threshold, [0.30, 0.35, 0.5]).addGrid(cl[2].maxIter, [1, 5]).addGrid(cl[2].elasticNetParam, [0.0, 0.5, 1]).build())\n",
    "cv3 = CrossValidator(estimator=pipeline[2], evaluator=BinaryClassificationEvaluator(), estimatorParamMaps=paramGrid3, numFolds=5)\n",
    "#cv3 = TrainValidationSplit(estimator=pipeline[2], evaluator=BinaryClassificationEvaluator(), estimatorParamMaps=paramGrid, trainRatio=0.8)\n",
    "model.insert(2, cv3.fit(train))\n",
    "print (\"Model 3 completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+-----------+---------+\n",
      "|            features|prediction|probability|trueLabel|\n",
      "+--------------------+----------+-----------+---------+\n",
      "|[1.0,2.6839006414...|       0.0|  [1.0,0.0]|        0|\n",
      "|[1.0,7.8092018663...|       0.0|  [1.0,0.0]|        0|\n",
      "|[1.0,8.3100019860...|       0.0|  [1.0,0.0]|        0|\n",
      "|[1.0,9.0937021733...|       0.0|  [1.0,0.0]|        0|\n",
      "|[1.0,1.2693803033...|       0.0|  [1.0,0.0]|        0|\n",
      "|[1.0,1.6969904055...|       0.0|  [1.0,0.0]|        0|\n",
      "|[1.0,3.4123508155...|       0.0|  [1.0,0.0]|        0|\n",
      "|[1.0,4.5162510793...|       0.0|  [1.0,0.0]|        0|\n",
      "|[1.0,5.2616512575...|       0.0|  [1.0,0.0]|        0|\n",
      "|[1.0,5.7945213848...|       0.0|  [1.0,0.0]|        0|\n",
      "|[1.0,6.2848915020...|       0.0|  [1.0,0.0]|        0|\n",
      "|[1.0,9.0027421516...|       0.0|  [1.0,0.0]|        0|\n",
      "|[1.0,9.2562422122...|       0.0|  [1.0,0.0]|        0|\n",
      "|[1.0,9.4654822622...|       0.0|  [1.0,0.0]|        0|\n",
      "|[1.0,9.5750622884...|       0.0|  [1.0,0.0]|        0|\n",
      "|[1.0,0.0010253812...|       0.0|  [1.0,0.0]|        0|\n",
      "|[1.0,0.0010389602...|       0.0|  [1.0,0.0]|        0|\n",
      "|[1.0,0.0010778722...|       0.0|  [1.0,0.0]|        0|\n",
      "|[1.0,0.0010842282...|       0.0|  [1.0,0.0]|        0|\n",
      "|[1.0,0.0011052752...|       0.0|  [1.0,0.0]|        0|\n",
      "|[1.0,0.0011434512...|       0.0|  [1.0,0.0]|        0|\n",
      "|[1.0,0.0012399412...|       0.0|  [1.0,0.0]|        0|\n",
      "|[1.0,0.0012743353...|       0.0|  [1.0,0.0]|        0|\n",
      "|[1.0,0.0013287483...|       0.0|  [1.0,0.0]|        0|\n",
      "|[1.0,0.0013792963...|       0.0|  [1.0,0.0]|        0|\n",
      "|[1.0,0.0014571623...|       0.0|  [1.0,0.0]|        0|\n",
      "|[1.0,0.0014765873...|       0.0|  [1.0,0.0]|        0|\n",
      "|[1.0,0.0015149763...|       0.0|  [1.0,0.0]|        0|\n",
      "|[1.0,0.0016218033...|       0.0|  [1.0,0.0]|        0|\n",
      "|[1.0,0.0016621843...|       0.0|  [1.0,0.0]|        0|\n",
      "+--------------------+----------+-----------+---------+\n",
      "only showing top 30 rows\n",
      "\n",
      "+--------------------+----------+-----------+---------+\n",
      "|            features|prediction|probability|trueLabel|\n",
      "+--------------------+----------+-----------+---------+\n",
      "|[1.0,2.6839006414...|       0.0|  [1.0,0.0]|        0|\n",
      "|[1.0,7.8092018663...|       0.0|  [1.0,0.0]|        0|\n",
      "|[1.0,8.3100019860...|       0.0|  [1.0,0.0]|        0|\n",
      "|[1.0,9.0937021733...|       0.0|  [1.0,0.0]|        0|\n",
      "|[1.0,1.2693803033...|       0.0|  [1.0,0.0]|        0|\n",
      "|[1.0,1.6969904055...|       0.0|  [1.0,0.0]|        0|\n",
      "|[1.0,3.4123508155...|       0.0|  [1.0,0.0]|        0|\n",
      "|[1.0,4.5162510793...|       0.0|  [1.0,0.0]|        0|\n",
      "|[1.0,5.2616512575...|       0.0|  [1.0,0.0]|        0|\n",
      "|[1.0,5.7945213848...|       0.0|  [1.0,0.0]|        0|\n",
      "|[1.0,6.2848915020...|       0.0|  [1.0,0.0]|        0|\n",
      "|[1.0,9.0027421516...|       0.0|  [1.0,0.0]|        0|\n",
      "|[1.0,9.2562422122...|       0.0|  [1.0,0.0]|        0|\n",
      "|[1.0,9.4654822622...|       0.0|  [1.0,0.0]|        0|\n",
      "|[1.0,9.5750622884...|       0.0|  [1.0,0.0]|        0|\n",
      "|[1.0,0.0010253812...|       0.0|  [1.0,0.0]|        0|\n",
      "|[1.0,0.0010389602...|       0.0|  [1.0,0.0]|        0|\n",
      "|[1.0,0.0010778722...|       0.0|  [1.0,0.0]|        0|\n",
      "|[1.0,0.0010842282...|       0.0|  [1.0,0.0]|        0|\n",
      "|[1.0,0.0011052752...|       0.0|  [1.0,0.0]|        0|\n",
      "|[1.0,0.0011434512...|       0.0|  [1.0,0.0]|        0|\n",
      "|[1.0,0.0012399412...|       0.0|  [1.0,0.0]|        0|\n",
      "|[1.0,0.0012743353...|       0.0|  [1.0,0.0]|        0|\n",
      "|[1.0,0.0013287483...|       0.0|  [1.0,0.0]|        0|\n",
      "|[1.0,0.0013792963...|       0.0|  [1.0,0.0]|        0|\n",
      "|[1.0,0.0014571623...|       0.0|  [1.0,0.0]|        0|\n",
      "|[1.0,0.0014765873...|       0.0|  [1.0,0.0]|        0|\n",
      "|[1.0,0.0015149763...|       0.0|  [1.0,0.0]|        0|\n",
      "|[1.0,0.0016218033...|       0.0|  [1.0,0.0]|        0|\n",
      "|[1.0,0.0016621843...|       0.0|  [1.0,0.0]|        0|\n",
      "+--------------------+----------+-----------+---------+\n",
      "only showing top 30 rows\n",
      "\n",
      "+--------------------+----------+--------------------+---------+\n",
      "|            features|prediction|         probability|trueLabel|\n",
      "+--------------------+----------+--------------------+---------+\n",
      "|[1.0,2.6839006414...|       0.0|[0.99624968095916...|        0|\n",
      "|[1.0,7.8092018663...|       0.0|[0.99753516702639...|        0|\n",
      "|[1.0,8.3100019860...|       0.0|[0.99626091551094...|        0|\n",
      "|[1.0,9.0937021733...|       0.0|[0.99494941558297...|        0|\n",
      "|[1.0,1.2693803033...|       0.0|[0.99758046871404...|        0|\n",
      "|[1.0,1.6969904055...|       0.0|[0.99675444345294...|        0|\n",
      "|[1.0,3.4123508155...|       0.0|[0.99569512356667...|        0|\n",
      "|[1.0,4.5162510793...|       0.0|[0.99625257030589...|        0|\n",
      "|[1.0,5.2616512575...|       0.0|[0.99730276647706...|        0|\n",
      "|[1.0,5.7945213848...|       0.0|[0.99510536355797...|        0|\n",
      "|[1.0,6.2848915020...|       0.0|[0.99647797392872...|        0|\n",
      "|[1.0,9.0027421516...|       0.0|[0.99443969880246...|        0|\n",
      "|[1.0,9.2562422122...|       0.0|[0.99524299552093...|        0|\n",
      "|[1.0,9.4654822622...|       0.0|[0.99412254563048...|        0|\n",
      "|[1.0,9.5750622884...|       0.0|[0.99444731933919...|        0|\n",
      "|[1.0,0.0010253812...|       0.0|[0.99608744086268...|        0|\n",
      "|[1.0,0.0010389602...|       0.0|[0.99656620992614...|        0|\n",
      "|[1.0,0.0010778722...|       0.0|[0.99418743124019...|        0|\n",
      "|[1.0,0.0010842282...|       0.0|[0.99694669392421...|        0|\n",
      "|[1.0,0.0011052752...|       0.0|[0.99708537579914...|        0|\n",
      "|[1.0,0.0011434512...|       0.0|[0.99678264403949...|        0|\n",
      "|[1.0,0.0012399412...|       0.0|[0.99702965138452...|        0|\n",
      "|[1.0,0.0012743353...|       0.0|[0.99412415284097...|        0|\n",
      "|[1.0,0.0013287483...|       0.0|[0.99432994000358...|        0|\n",
      "|[1.0,0.0013792963...|       0.0|[0.99611104335105...|        0|\n",
      "|[1.0,0.0014571623...|       0.0|[0.99590998526247...|        0|\n",
      "|[1.0,0.0014765873...|       0.0|[0.99791456407964...|        0|\n",
      "|[1.0,0.0015149763...|       0.0|[0.99842917414838...|        0|\n",
      "|[1.0,0.0016218033...|       0.0|[0.99615114719097...|        0|\n",
      "|[1.0,0.0016621843...|       0.0|[0.99806195902400...|        0|\n",
      "+--------------------+----------+--------------------+---------+\n",
      "only showing top 30 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Test the model\n",
    "prediction = [] \n",
    "predicted = []\n",
    "for i in range(3):\n",
    "  prediction.insert(i, model[i].transform(test))\n",
    "  predicted.insert(i, prediction[i].select(\"features\", \"prediction\", \"probability\", \"trueLabel\"))\n",
    "  predicted[i].show(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AreaUnderPR = 0.809319 \n",
      "AreaUnderROC = 0.807692 \n",
      "Precision = 1 \n",
      "Recall = 0.615385 \n",
      "+---------+------------------+\n",
      "|   metric|             value|\n",
      "+---------+------------------+\n",
      "|       TP|              16.0|\n",
      "|       FP|               0.0|\n",
      "|       TN|            3048.0|\n",
      "|       FN|              10.0|\n",
      "|Precision|               1.0|\n",
      "|   Recall|0.6153846153846154|\n",
      "+---------+------------------+\n",
      "\n",
      "AreaUnderPR = 0.828387 \n",
      "AreaUnderROC = 0.826923 \n",
      "Precision = 1 \n",
      "Recall = 0.653846 \n",
      "+---------+------------------+\n",
      "|   metric|             value|\n",
      "+---------+------------------+\n",
      "|       TP|              17.0|\n",
      "|       FP|               0.0|\n",
      "|       TN|            3048.0|\n",
      "|       FN|               9.0|\n",
      "|Precision|               1.0|\n",
      "|   Recall|0.6538461538461539|\n",
      "+---------+------------------+\n",
      "\n",
      "AreaUnderPR = 0.523297 \n",
      "AreaUnderROC = 0.519231 \n",
      "Precision = 1 \n",
      "Recall = 0.0384615 \n",
      "+---------+--------------------+\n",
      "|   metric|               value|\n",
      "+---------+--------------------+\n",
      "|       TP|                 1.0|\n",
      "|       FP|                 0.0|\n",
      "|       TN|              3048.0|\n",
      "|       FN|                25.0|\n",
      "|Precision|                 1.0|\n",
      "|   Recall|0.038461538461538464|\n",
      "+---------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(\n",
    "    labelCol=\"trueLabel\", rawPredictionCol=\"prediction\")\n",
    "for i in range(3):\n",
    "    #evaluator = MulticlassClassificationEvaluator(\n",
    "    #labelCol=\"trueLabel\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
    "    areUPR = evaluator.evaluate(predicted[i], {evaluator.metricName: \"areaUnderPR\"})\n",
    "    areUROC = evaluator.evaluate(predicted[i], {evaluator.metricName: \"areaUnderROC\"})\n",
    "    print(\"AreaUnderPR = %g \" % (areUPR))\n",
    "    \n",
    "    print(\"AreaUnderROC = %g \" % (areUROC))\n",
    "\n",
    "    tp = float(predicted[i].filter(\"prediction == 1.0 AND truelabel == 1\").count())\n",
    "    fp = float(predicted[i].filter(\"prediction == 1.0 AND truelabel == 0\").count())\n",
    "    tn = float(predicted[i].filter(\"prediction == 0.0 AND truelabel == 0\").count())\n",
    "    fn = float(predicted[i].filter(\"prediction == 0.0 AND truelabel == 1\").count())\n",
    "\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    print(\"Precision = %g \" % (precision))\n",
    "    print(\"Recall = %g \" % (recall))\n",
    "\n",
    "    metrics = sqlContext.createDataFrame([\n",
    "    (\"TP\", tp),\n",
    "    (\"FP\", fp),\n",
    "    (\"TN\", tn),\n",
    "    (\"FN\", fn),\n",
    "    (\"Precision\", tp / (tp + fp)),\n",
    "    (\"Recall\", tp / (tp + fn))],[\"metric\", \"value\"])\n",
    "    metrics.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "name": "Fraud_Detection",
  "notebookId": 688002291907907
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
